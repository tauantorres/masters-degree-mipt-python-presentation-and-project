{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "998a43f9",
   "metadata": {},
   "source": [
    "## 1. Framework overviews\n",
    "\n",
    "### Dataclasses\n",
    "\n",
    "**What it is**\n",
    "The dataclasses module (introduced in Python 3.7) provides a decorator `@dataclass` that lets you define classes whose primary purpose is storing data, with automatically generated `__init__()`, `__repr__()`, `__eq__()`, etc. ([Python documentation][1])\n",
    "You can specify default values, factories, make classes frozen (immutable), etc.\n",
    "\n",
    "**Typical usage**\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class User:\n",
    "    id: int\n",
    "    name: str\n",
    "    tags: list[str] = field(default_factory=list)\n",
    "```\n",
    "\n",
    "**Key features**\n",
    "\n",
    "* Minimal boilerplate for data containers. ([realpython.com][2])\n",
    "* Works purely in standard library, no external dependency.\n",
    "* Good for simple “just hold data” use-cases.\n",
    "* Supports default values, `__post_init__`, optional immutability via `frozen=True`, conversion to dict/tuple via `asdict()`, `astuple()` etc. ([Python documentation][1])\n",
    "\n",
    "**When you might use it**\n",
    "\n",
    "* Internal models, configuration objects, lightweight containers.\n",
    "* Cases where you don’t need heavy validation, serialization features, or external integrations.\n",
    "\n",
    "---\n",
    "\n",
    "### Pydantic v2\n",
    "\n",
    "**What it is**\n",
    "Pydantic is a library built around data models (via `BaseModel`) with strong support for validation, parsing/coercion, serialization, type hints, etc. Version 2 is a major rewrite: it uses a Rust-based core (`pydantic-core`) for performance, has stricter modes, improved type handling and JSON support. ([pydantic.dev][3])\n",
    "\n",
    "**Typical usage**\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class User(BaseModel):\n",
    "    id: int\n",
    "    name: str = Field(alias=\"username\")\n",
    "    tags: list[str] = []\n",
    "```\n",
    "\n",
    "You can `.model_dump()`, `.model_dump_json()` etc to export, you get validation errors, nested models, validators, strict mode, etc.\n",
    "\n",
    "**Key features**\n",
    "\n",
    "* Strong validation/coercion: e.g., input types can be coerced or strict. ([Leapcell][4])\n",
    "* Serialization & parsing built in (including JSON).\n",
    "* Integration with many frameworks (e.g., web frameworks, settings, etc.).\n",
    "* Nested models, complex type hints, validators, custom fields.\n",
    "* With v2 improvements: better performance, strict mode, improved start-up/schema build times. ([pydantic.dev][5])\n",
    "\n",
    "**When you might use it**\n",
    "\n",
    "* When you receive external data (e.g., user input, API request) and you must validate/parse it.\n",
    "* When you need nested models, expressive validation logic, JSON schema generation, etc.\n",
    "* When you want good developer ergonomics (rich error messages, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### Msgspec\n",
    "\n",
    "**What it is**\n",
    "Msgspec is a relatively newer library oriented around ultra-fast serialization/deserialization and validation of structured data. It offers `Struct` types (and `TypedDict`-style) and focuses heavily on performance. ([jcristharif.com][6])\n",
    "\n",
    "**Typical usage**\n",
    "\n",
    "```python\n",
    "import msgspec\n",
    "\n",
    "class User(msgspec.Struct, kw_only=True):\n",
    "    id: int\n",
    "    name: str\n",
    "    tags: list[str]\n",
    "```\n",
    "\n",
    "It supports `msgspec.json.decode(...)`, `msgspec.json.encode(...)`, MessagePack, etc.\n",
    "\n",
    "**Key features**\n",
    "\n",
    "* Very high performance for both decoding (JSON → object) and encoding (object → JSON/MsgPack) when schema is known. ([hrekov.com][7])\n",
    "* Low memory overhead and optimized implementation (C/Rust backends). ([jcristharif.com][6])\n",
    "* Designed for high-throughput scenarios (e.g., pipelines, microservices) where serialization cost is significant.\n",
    "* Simpler, more focused model: fewer bells and whistles than Pydantic (less heavy validation ecosystem). ([hrekov.com][8])\n",
    "\n",
    "**When you might use it**\n",
    "\n",
    "* Data‐intensive systems where serialization/deserialization is performance critical.\n",
    "* Scenarios where you trust data shape (schema known ahead) and you don’t need extremely rich validation logic.\n",
    "* Microservices, high throughput event processing, internal APIs where speed matters.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Differences between them\n",
    "\n",
    "Here’s a comparative view of how they differ along key dimensions:\n",
    "\n",
    "| Framework   | Purpose / Focus                                               | Validation & parsing support                                     | Serialization features                                   | Ecosystem / integrations                      | Overhead / complexity                                            |\n",
    "| ----------- | ------------------------------------------------------------- | ---------------------------------------------------------------- | -------------------------------------------------------- | --------------------------------------------- | ---------------------------------------------------------------- |\n",
    "| Dataclasses | Simple data containers (state only)                           | Minimal or none (you’d add manual checks)                        | Basic – you can convert to dict/tuple (`asdict`)         | Built-in to Python standard library           | Very low overhead; minimal runtime logic                         |\n",
    "| Pydantic v2 | Data modelling + validation + serialization                   | Strong: nested models, coercion, strict mode                     | Good: `.model_dump()`, `.model_dump_json()`, JSON schema | Widely used in web frameworks (FastAPI, etc)  | More overhead than dataclasses; schema building cost             |\n",
    "| Msgspec     | Ultra‐fast serialization & deserialization of structured data | Validation/typing with struct types (more limited than Pydantic) | Excellent performance for encode/decode JSON/MsgPack     | Emerging; less “bulk ecosystem” than Pydantic | Very low overhead for data paths; but fewer convenience features |\n",
    "\n",
    "**More fine‐grain difference notes**:\n",
    "\n",
    "* Dataclasses don’t inherently validate types beyond runtime typing hints; many fields might just hold wrong types unless you manually enforce.\n",
    "* Pydantic adds type validation/coercion plus rich features like custom validators, aliasing, settings support etc.\n",
    "* Msgspec sacrifices some of the richer validation/utility features (in favor of speed) — for instance custom nested validation, deep error messages, convenience methods are less extensive. ([hrekov.com][8])\n",
    "* Startup/schema build time: Pydantic has overhead building its core schemas (especially if many models) whereas dataclasses are trivial; msgspec also builds schema but is optimized for speed.\n",
    "* Memory/obj overhead: Dataclasses have minimal overhead; msgspec benchmarks show much lower memory usage compared to many other frameworks. ([jcristharif.com][6])\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Pros & cons\n",
    "\n",
    "Here is a pros/cons list for each framework.\n",
    "\n",
    "### Dataclasses\n",
    "\n",
    "**Pros**\n",
    "\n",
    "* Very lightweight, built into Python library (no third-party dependency).\n",
    "* Minimal boilerplate for defining simple data containers.\n",
    "* Low runtime overhead, fast instantiation.\n",
    "* Clear semantics, easy to read.\n",
    "* Good when you just need containers, no heavy validation/serialization.\n",
    "\n",
    "**Cons**\n",
    "\n",
    "* Almost no built‐in validation/coercion (beyond what you manually code).\n",
    "* For serialization/parsing you’ll often need other libraries (or custom code).\n",
    "* No built‐in advanced features like aliasing, JSON schema generation, nested model validation, etc.\n",
    "* Not specialized for high‐throughput serialization scenarios.\n",
    "\n",
    "### Pydantic v2\n",
    "\n",
    "**Pros**\n",
    "\n",
    "* Strong validation/parsing support: build models, parse from dict/JSON, validate types, nested models, strict/coercion modes.\n",
    "* Good serialization/dumping tools (.model_dump, .model_dump_json).\n",
    "* Rich integration with many frameworks (web, settings, etc).\n",
    "* Developer ergonomics: error messages, validators, aliases.\n",
    "* Performance improved in v2 (Rust core, etc). ([pydantic.dev][3])\n",
    "\n",
    "**Cons**\n",
    "\n",
    "* More overhead (both at runtime and at startup) than simple dataclasses.\n",
    "* Some complexity: learning curve for config/validators, nested rules.\n",
    "* For extremely high throughput workloads, may still lag behind specialized alternatives (like msgspec) in pure serialization speed.\n",
    "* Migration from v1 to v2 may involve changes. ([docs.pydantic.dev][9])\n",
    "\n",
    "### Msgspec\n",
    "\n",
    "**Pros**\n",
    "\n",
    "* Exceptional performance in serialization/deserialization (benchmarks show strong lead). ([hrekov.com][7])\n",
    "* Low memory overhead, efficient data handling. ([jcristharif.com][6])\n",
    "* Good when you know schema ahead and you need throughput.\n",
    "* Supports JSON, MessagePack and other formats (helpful for data pipelines).\n",
    "\n",
    "**Cons**\n",
    "\n",
    "* Less feature‐rich (“fewer convenience” features) compared to Pydantic: less mature ecosystem of validators/customization. ([hrekov.com][8])\n",
    "* Error messages/validation may be less rich; nested complex validation logic may require more boilerplate.\n",
    "* Not always the best choice for scenarios where developer productivity/features matter more than raw speed.\n",
    "* Some learning curve: you need to use its Struct types, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Efficiency / performance analysis\n",
    "\n",
    "Since you asked specifically about “which one is fast and why”, here’s an analysis based on available benchmarks plus reasoning.\n",
    "\n",
    "### Performance evidence\n",
    "\n",
    "* Benchmarks for msgspec show that it is typically **2-5× faster** than Pydantic v2 for decoding and encoding in many cases. ([hrekov.com][7])\n",
    "* In one benchmark: msgspec vs Pydantic v2: For decoding, ~40k ops/sec vs ~12k ops/sec (≈3.3× faster) in that case. ([hrekov.com][7])\n",
    "* Another benchmark shows very large gaps: e.g., in a gist: pydantic v2 ~14× slower than msgspec for certain JSON workloads. ([Gist][10])\n",
    "* For simple dataclasses vs Pydantic: one blog found dataclasses ~6.5× faster for instance creation from dict compared to Pydantic (when validation/coercion is minimal) using a simple model. ([Lee Han Chung][11])\n",
    "* Benchmarks for msgspec vs other libs: msgspec ~12× faster than Pydantic v2 in one benchmark of JSON serialization/validation. ([jcristharif.com][6])\n",
    "\n",
    "### Why the difference (reasoning)\n",
    "\n",
    "**Dataclasses**:\n",
    "\n",
    "* Since dataclasses generate minimal boilerplate and have no built-in heavy parsing/validation logic, instantiating them is cheap. No runtime type checking or schema building overhead by default.\n",
    "* Example: creation of instances is faster, fewer allocations overlaying validation etc. ([Lee Han Chung][11])\n",
    "\n",
    "**Pydantic v2**:\n",
    "\n",
    "* Adds overhead: building internal schema, validation/coercion, conversion, and object creation of model classes. Even though v2 has improved performance (Rust core), there is still overhead relative to “plain object”.\n",
    "* More flexible features cost something: type coercion, nested model instantiation, aliasing etc all add steps.\n",
    "* Startup/schema build: if you have many models or nested models, this cost becomes more noticeable. For example v2.11 improved startup time and memory usage substantially. ([pydantic.dev][5])\n",
    "\n",
    "**Msgspec**:\n",
    "\n",
    "* Designed for speed: uses compiled backend (C/Rust) optimized for serialization/deserialization, avoids many Python‐level loops, fewer intermediate allocations. ([hrekov.com][7])\n",
    "* When decoding with known schema (Struct), it can validate at the same time as decode, avoiding a second pass. This reduces overhead of creating intermediate dicts then models. ([jcristharif.com][6])\n",
    "* Lower memory overhead means fewer GC pauses, fewer allocations, more cache-friendly behaviour. ([jcristharif.com][6])\n",
    "\n",
    "### Practical implications\n",
    "\n",
    "* If you are *just* storing data (no heavy parsing/validation, schema stable, internal use), **dataclasses** will probably be the fastest/easiest.\n",
    "* If you must validate/parse external data (API requests, JSON with unknown shape, nested models) and want good ergonomics, **Pydantic v2** is a strong choice — its overhead is acceptable in many use cases.\n",
    "* If you operate in a high‐throughput scenario (many thousands of messages per second, need minimal latency/serialization overhead) and you know your schema is fixed/stable, **msgspec** is likely the best performer (but you trade some convenience).\n",
    "* Also note: performance differences may matter most in large loops, high volume data processes, or latency‐sensitive services. For smaller or less performance-critical uses, the difference may be negligible and other factors (developer productivity, readability) may dominate.\n",
    "\n",
    "### Some caveats\n",
    "\n",
    "* Benchmarks depend on workload, data size, depth of nesting, types used (floats, strings, arrays). In one case, `msgspec`’s float parser was slightly slower than orjson’s because of type specifics. ([Gist][12])\n",
    "* For many real-world cases, overhead may not be the dominating factor; other bottlenecks (I/O, DB, network) may dwarf these differences.\n",
    "* Schema build/startup time matters more for large model sets; if you only build once at startup, the per‐use cost might be small.\n",
    "* Features vs speed tradeoff: richer validation logic (custom validators, nested coercion) will cost time regardless of library.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Recommendations based on context\n",
    "\n",
    "Here are some general suggested guidelines:\n",
    "\n",
    "* If we need **simple models** (just storing state, few fields, internal use) → use dataclasses.\n",
    "* If we need **validation / parsing of external input**, nested models, aliasing, etc → use Pydantic v2.\n",
    "* If we are building a **performance-sensitive pipeline** (lots of messages, high throughput, streaming, serialization bottleneck) and our schema is fixed → consider msgspec.\n",
    "* We might even mix: e.g., use Pydantic at service boundaries (for request/response validation) and internal use dataclasses or msgspec for internal high-throughput data flows.\n",
    "\n",
    "\n",
    "[1]: https://docs.python.org/3/library/dataclasses.html?utm_source=chatgpt.com \"dataclasses — Data Classes\"\n",
    "[2]: https://realpython.com/ref/stdlib/dataclasses/?utm_source=chatgpt.com \"dataclasses | Python Standard Library\"\n",
    "[3]: https://pydantic.dev/articles/pydantic-v2?utm_source=chatgpt.com \"Introducing Pydantic v2 - Key Features\"\n",
    "[4]: https://leapcell.io/blog/deep-dive-into-pydantic-v2-core-changes?utm_source=chatgpt.com \"Deep Dive into Pydantic V2 Core Changes\"\n",
    "[5]: https://pydantic.dev/articles/pydantic-v2-11-release?utm_source=chatgpt.com \"Announcement: Pydantic v2.11 Release\"\n",
    "[6]: https://jcristharif.com/msgspec/benchmarks.html?utm_source=chatgpt.com \"Benchmarks - msgspec\"\n",
    "[7]: https://hrekov.com/blog/msgspec-vs-pydantic-v2-benchmark?utm_source=chatgpt.com \"Benchmark: msgspec vs. Pydantic v2 - Hrekov\"\n",
    "[8]: https://hrekov.com/blog/msgspec-vs-pydantic-drawbacks?utm_source=chatgpt.com \"Drawbacks of Msgspec Compared to Pydantic: A Deep Dive ...\"\n",
    "[9]: https://docs.pydantic.dev/latest/migration/?utm_source=chatgpt.com \"Migration Guide - Pydantic Validation\"\n",
    "[10]: https://gist.github.com/jcrist/d62f450594164d284fbea957fd48b743?utm_source=chatgpt.com \"A quick benchmark comparing msgspec (https://github.com ...\"\n",
    "[11]: https://leehanchung.github.io/blogs/2025/07/03/pydantic-is-all-you-need-for-performance-spaghetti/?utm_source=chatgpt.com \"Pydantic Is All You Need for Poor Performance Spaghetti Code\"\n",
    "[12]: https://gist.github.com/jcrist/80b84817e9c53a63222bd905aa607b43?utm_source=chatgpt.com \"Benchmark of msgspec, orjson, pydantic ...\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e58dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiation (µs per loop):\n",
      "dataclasses: 1.3430824999886681\n",
      "pydantic: 2.232855420006672\n",
      "msgspec: 0.16341124999598833\n",
      "\n",
      "Serialization (µs per loop):\n",
      "dataclasses: 12.98015291999036\n",
      "pydantic: 3.5415187499893364\n",
      "msgspec: 0.42775333000463434\n",
      "\n",
      "Deserialization (µs per loop):\n",
      "dataclasses: 14.33774416000233\n",
      "pydantic: 1.9399262499791803\n",
      "msgspec: 0.4351062500063563\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import json\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List\n",
    "\n",
    "# ===== Setup dataclasses version =====\n",
    "@dataclass\n",
    "class AddressDC:\n",
    "    street: str\n",
    "    city: str\n",
    "    country: str\n",
    "    postal_code: str\n",
    "\n",
    "@dataclass\n",
    "class UserDC:\n",
    "    id: int\n",
    "    name: str\n",
    "    email: str\n",
    "    age: int\n",
    "    is_active: bool\n",
    "    address: AddressDC\n",
    "    tags: List[str]\n",
    "\n",
    "def make_user_dc():\n",
    "    return UserDC(\n",
    "        id=1,\n",
    "        name=\"Alice\",\n",
    "        email=\"alice@example.com\",\n",
    "        age=30,\n",
    "        is_active=True,\n",
    "        address=AddressDC(\n",
    "            street=\"123 Main St\", city=\"Hometown\", country=\"USA\", postal_code=\"12345\"\n",
    "        ),\n",
    "        tags=[\"admin\",\"user\"]\n",
    "    )\n",
    "\n",
    "def serialize_dc():\n",
    "    ud = make_user_dc()\n",
    "    return json.dumps(asdict(ud)).encode()\n",
    "\n",
    "def deserialize_dc(b: bytes):\n",
    "    return json.loads(b)\n",
    "\n",
    "# ===== Setup Pydantic version =====\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class AddressPD(BaseModel):\n",
    "    street: str\n",
    "    city: str\n",
    "    country: str\n",
    "    postal_code: str\n",
    "\n",
    "class UserPD(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "    email: str\n",
    "    age: int\n",
    "    is_active: bool\n",
    "    address: AddressPD\n",
    "    tags: List[str]\n",
    "\n",
    "def make_user_pd():\n",
    "    return UserPD(\n",
    "        id=1,\n",
    "        name=\"Alice\",\n",
    "        email=\"alice@example.com\",\n",
    "        age=30,\n",
    "        is_active=True,\n",
    "        address=AddressPD(\n",
    "            street=\"123 Main St\", city=\"Hometown\", country=\"USA\", postal_code=\"12345\"\n",
    "        ),\n",
    "        tags=[\"admin\",\"user\"]\n",
    "    )\n",
    "\n",
    "def serialize_pd():\n",
    "    up = make_user_pd()\n",
    "    # using Pydantic v2: .model_dump_json() returns str\n",
    "    return up.model_dump_json().encode()\n",
    "\n",
    "def deserialize_pd(b: bytes):\n",
    "    # parse raw JSON into model\n",
    "    return UserPD.model_validate_json(b)\n",
    "\n",
    "# ===== Setup msgspec version =====\n",
    "import msgspec\n",
    "\n",
    "\n",
    "class AddressMS(msgspec.Struct, kw_only=True):\n",
    "    street: str\n",
    "    city: str\n",
    "    country: str\n",
    "    postal_code: str\n",
    "\n",
    "class UserMS(msgspec.Struct, kw_only=True):\n",
    "    id: int\n",
    "    name: str\n",
    "    email: str\n",
    "    age: int\n",
    "    is_active: bool\n",
    "    address: AddressMS\n",
    "    tags: List[str]\n",
    "\n",
    "def make_user_ms():\n",
    "    return UserMS(\n",
    "        id=1,\n",
    "        name=\"Alice\",\n",
    "        email=\"alice@example.com\",\n",
    "        age=30,\n",
    "        is_active=True,\n",
    "        address=AddressMS(\n",
    "            street=\"123 Main St\", city=\"Hometown\", country=\"USA\", postal_code=\"12345\"\n",
    "        ),\n",
    "        tags=[\"admin\",\"user\"]\n",
    "    )\n",
    "\n",
    "# Pre-encode one example for deserialization test\n",
    "_ms_json = msgspec.json.encode(make_user_ms())\n",
    "_pd_json = serialize_pd()\n",
    "\n",
    "\n",
    "def serialize_ms():\n",
    "    um = make_user_ms()\n",
    "    return msgspec.json.encode(um)\n",
    "\n",
    "def deserialize_ms():\n",
    "    return msgspec.json.decode(_ms_json, type=UserMS)\n",
    "\n",
    "# ===== Benchmarking =====\n",
    "def benchmark(fn, loops=100_000):\n",
    "    t = timeit.timeit(fn, number=loops)\n",
    "    return (t / loops) * 1e6  # microseconds per loop\n",
    "\n",
    "loops = 100_000\n",
    "print(\"Instantiation (µs per loop):\")\n",
    "print(\"dataclasses:\", benchmark(make_user_dc, loops))\n",
    "print(\"pydantic:\",   benchmark(make_user_pd, loops))\n",
    "print(\"msgspec:\",     benchmark(make_user_ms, loops))\n",
    "\n",
    "print(\"\\nSerialization (µs per loop):\")\n",
    "print(\"dataclasses:\", benchmark(serialize_dc, loops))\n",
    "print(\"pydantic:\",   benchmark(serialize_pd, loops))\n",
    "print(\"msgspec:\",     benchmark(serialize_ms, loops))\n",
    "\n",
    "print(\"\\nDeserialization (µs per loop):\")\n",
    "print(\"dataclasses:\", benchmark(lambda: deserialize_dc(serialize_dc()), loops))\n",
    "print(\"pydantic:\",   benchmark(lambda: deserialize_pd(_pd_json), loops))\n",
    "print(\"msgspec:\",     benchmark(deserialize_ms, loops))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab0caf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f826805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a08f0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9a409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c86ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
