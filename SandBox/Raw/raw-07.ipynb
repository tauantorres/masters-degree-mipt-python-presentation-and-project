{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07c79041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_dataclass import instantiate_dataclass, encode_dataclass, decode_dataclass\n",
    "from benchmark_pydantic import instantiate_pydantic, encode_pydantic, decode_pydantic\n",
    "from benchmark_msgspec import instantiate_msgspec, encode_msgspec, decode_msgspec\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e2509e",
   "metadata": {},
   "source": [
    "## 1. Generate Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdecfe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from time import perf_counter\n",
    "from data_generator import generate_users_batch\n",
    "\n",
    "\n",
    "batch_size = 1_000\n",
    "users_data = generate_users_batch(batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45efcf5",
   "metadata": {},
   "source": [
    "# 2. Microbenchmark:\n",
    "\n",
    "* Running the benchmark for each library with the generated data with a batch size of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b43b141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_benchmark(fn, obj, iterations=50_000):\n",
    "    times = []\n",
    "    for _ in range(iterations):\n",
    "        start = perf_counter()\n",
    "        fn(obj)\n",
    "        end = perf_counter()\n",
    "        times.append(end - start)\n",
    "\n",
    "    avg_us = statistics.mean(times) * 1e6\n",
    "    return avg_us\n",
    "\n",
    "def batch_benchmark(fn, batch):\n",
    "    start = perf_counter()\n",
    "    for item in batch:\n",
    "        fn(item)\n",
    "    end = perf_counter()\n",
    "    total = end - start\n",
    "    avg_us = (total / len(batch)) * 1e6\n",
    "    return avg_us, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ba984d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Microbenchmark: single-object repeated ===\n",
      "\n",
      "Dataclass: instantiate = 0.39 µs\n",
      "Pydantic:  instantiate = 1.17 µs\n",
      "Msgspec:   instantiate = 0.17 µs\n",
      "\n",
      "Dataclass: encode = 2.75 µs\n",
      "Pydantic:  encode = 0.75 µs\n",
      "Msgspec:   encode = 0.14 µs\n",
      "\n",
      "Dataclass: decode = 1.44 µs\n",
      "Pydantic:  decode = 0.86 µs\n",
      "Msgspec:   decode = 0.21 µs\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "single_user = generate_users_batch(batch_size=batch_size)[0]\n",
    "\n",
    "# Instantiate objects for encoding/decoding\n",
    "dc_obj = instantiate_dataclass(single_user)\n",
    "py_obj = instantiate_pydantic(single_user)\n",
    "ms_obj = instantiate_msgspec(single_user)\n",
    "\n",
    "# Encode once\n",
    "dc_encoded = encode_dataclass(dc_obj)\n",
    "py_encoded = encode_pydantic(py_obj)\n",
    "ms_encoded = encode_msgspec(ms_obj)\n",
    "\n",
    "print(\"=== Microbenchmark: single-object repeated ===\\n\")\n",
    "print(f\"Dataclass: instantiate = {micro_benchmark(instantiate_dataclass, single_user):.2f} µs\")\n",
    "print(f\"Pydantic:  instantiate = {micro_benchmark(instantiate_pydantic, single_user):.2f} µs\")\n",
    "print(f\"Msgspec:   instantiate = {micro_benchmark(instantiate_msgspec, single_user):.2f} µs\\n\")\n",
    "\n",
    "print(f\"Dataclass: encode = {micro_benchmark(lambda _: encode_dataclass(dc_obj), None):.2f} µs\")\n",
    "print(f\"Pydantic:  encode = {micro_benchmark(lambda _: encode_pydantic(py_obj), None):.2f} µs\")\n",
    "print(f\"Msgspec:   encode = {micro_benchmark(lambda _: encode_msgspec(ms_obj), None):.2f} µs\\n\")\n",
    "\n",
    "print(f\"Dataclass: decode = {micro_benchmark(lambda _: decode_dataclass(dc_encoded), None):.2f} µs\")\n",
    "print(f\"Pydantic:  decode = {micro_benchmark(lambda _: decode_pydantic(py_encoded), None):.2f} µs\")\n",
    "print(f\"Msgspec:   decode = {micro_benchmark(lambda _: decode_msgspec(ms_encoded), None):.2f} µs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc014cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch Benchmark: many objects once ===\n",
      "Dataclass instantiate avg = 0.22 µs\n",
      "Pydantic instantiate avg = 0.72 µs\n",
      "Msgspec  instantiate avg = 0.15 µs\n",
      "\n",
      "--- Encoding ---\n",
      "Dataclass encode = 2.84 µs\n",
      "Pydantic encode = 0.80 µs\n",
      "Msgspec encode = 0.12 µs\n",
      "\n",
      "--- Decoding ---\n",
      "Dataclass decode = 1.42 µs\n",
      "Pydantic decode = 0.93 µs\n",
      "Msgspec decode = 0.23 µs\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1_000_000\n",
    "users = generate_users_batch(batch_size)\n",
    "\n",
    "print(\"\\n=== Batch Benchmark: many objects once ===\")\n",
    "\n",
    "# Instantiation benchmark\n",
    "print(f\"Dataclass instantiate avg = {batch_benchmark(instantiate_dataclass, users)[0]:.2f} µs\")\n",
    "print(f\"Pydantic instantiate avg = {batch_benchmark(instantiate_pydantic, users)[0]:.2f} µs\")\n",
    "print(f\"Msgspec  instantiate avg = {batch_benchmark(instantiate_msgspec, users)[0]:.2f} µs\")\n",
    "\n",
    "dc_objs  = [instantiate_dataclass(u) for u in users]\n",
    "py_objs  = [instantiate_pydantic(u) for u in users]\n",
    "ms_objs  = [instantiate_msgspec(u) for u in users]\n",
    "\n",
    "print(\"\\n--- Encoding ---\")\n",
    "print(f\"Dataclass encode = {batch_benchmark(encode_dataclass, dc_objs)[0]:.2f} µs\")\n",
    "print(f\"Pydantic encode = {batch_benchmark(encode_pydantic, py_objs)[0]:.2f} µs\")\n",
    "print(f\"Msgspec encode = {batch_benchmark(encode_msgspec, ms_objs)[0]:.2f} µs\")\n",
    "\n",
    "dc_bin  = [encode_dataclass(o) for o in dc_objs]\n",
    "py_bin  = [encode_pydantic(o) for o in py_objs]\n",
    "ms_bin  = [encode_msgspec(o) for o in ms_objs]\n",
    "\n",
    "print(\"\\n--- Decoding ---\")\n",
    "print(f\"Dataclass decode = {batch_benchmark(decode_dataclass, dc_bin)[0]:.2f} µs\")\n",
    "print(f\"Pydantic decode = {batch_benchmark(decode_pydantic, py_bin)[0]:.2f} µs\")\n",
    "print(f\"Msgspec decode = {batch_benchmark(decode_msgspec, ms_bin)[0]:.2f} µs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe98a348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
